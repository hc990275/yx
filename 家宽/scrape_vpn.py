import os
import requests
from bs4 import BeautifulSoup
import datetime
import re

# ä»ç¯å¢ƒå˜é‡è·å– URLï¼Œå¦‚æœæœ¬åœ°è¿è¡Œåˆ™ä½¿ç”¨é»˜è®¤å€¼
TARGET_URL = os.getenv('TARGET_URL', 'https://ipspeed.info/free-l2tpipsec.php')

# å›½å®¶åç§°æ˜ å°„ (è‹±æ–‡ -> ç®€ä½“ä¸­æ–‡)
COUNTRY_MAP = {
    "Japan": "æ—¥æœ¬",
    "Republic of Korea": "éŸ©å›½",
    "United States": "ç¾å›½",
    "United Kingdom": "è‹±å›½",
    "Germany": "å¾·å›½",
    "France": "æ³•å›½",
    "Netherlands": "è·å…°",
    "Singapore": "æ–°åŠ å¡",
    "Canada": "åŠ æ‹¿å¤§",
    "Russia": "ä¿„ç½—æ–¯",
    "India": "å°åº¦",
    "Australia": "æ¾³å¤§åˆ©äºš",
    "China": "ä¸­å›½",
    "Hong Kong": "ä¸­å›½é¦™æ¸¯",
    "Taiwan": "ä¸­å›½å°æ¹¾",
    "Brazil": "å·´è¥¿",
    "Vietnam": "è¶Šå—",
    "Thailand": "æ³°å›½",
    "Indonesia": "å°åº¦å°¼è¥¿äºš",
    "Turkey": "åœŸè€³å…¶"
}

def translate_country(english_name):
    """å°†è‹±æ–‡å›½å®¶åè½¬æ¢ä¸ºä¸­æ–‡"""
    clean_name = english_name.strip()
    return COUNTRY_MAP.get(clean_name, clean_name)

def parse_uptime_to_minutes(uptime_str):
    """
    å°†åœ¨çº¿æ—¶é—´å­—ç¬¦ä¸² (e.g., '60 days', '0 mins', '2 hours') è½¬æ¢ä¸ºåˆ†é’Ÿæ•°ç”¨äºæ’åºã€‚
    """
    uptime_str = uptime_str.lower().strip()
    
    # æå–æ•°å­—
    match = re.search(r'(\d+)', uptime_str)
    if not match:
        return float('inf') # æ— æ³•è§£æåˆ™æ”¾åˆ°æœ€å
    
    value = int(match.group(1))
    
    if 'day' in uptime_str:
        return value * 24 * 60
    elif 'hour' in uptime_str:
        return value * 60
    elif 'min' in uptime_str:
        return value
    elif 'sec' in uptime_str:
        return 0 # ç§’çº§è§†ä¸º0åˆ†é’Ÿ
    
    return value

def scrape_and_generate_readme():
    print(f"æ­£åœ¨æŠ“å–: {TARGET_URL}")
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    try:
        response = requests.get(TARGET_URL, headers=headers, timeout=20)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
    except Exception as e:
        print(f"è¯·æ±‚å¤±è´¥: {e}")
        return

    # å®šä½è¡¨æ ¼
    table = soup.find('table', class_='table table-success table-striped text-nowrap')
    if not table:
        print("é”™è¯¯: æœªæ‰¾åˆ°ç›®æ ‡è¡¨æ ¼ã€‚")
        return

    vpn_nodes = []
    
    tbody = table.find('tbody')
    rows = tbody.find_all('tr') if tbody else []

    for row in rows:
        cols = row.find_all('td')
        # è¡¨æ ¼ç»“æ„: # (th), Location (td), IP (td), Uptime (td), Ping (td)
        if len(cols) >= 4:
            location_raw = cols[0].get_text(strip=True)
            ip_address = cols[1].get_text(strip=True)
            uptime_str = cols[2].get_text(strip=True)
            ping = cols[3].get_text(strip=True)

            location_cn = translate_country(location_raw)
            uptime_minutes = parse_uptime_to_minutes(uptime_str)

            vpn_nodes.append({
                "location": location_cn,
                "ip": ip_address,
                "uptime_str": uptime_str,
                "uptime_minutes": uptime_minutes, # ç”¨äºæ’åº
                "ping": ping
            })

    # æ ¸å¿ƒé€»è¾‘ï¼šæŒ‰ç…§è¿è¡Œæ—¶é—´æ’åºï¼ˆä»å°åˆ°å¤§ï¼ŒçŸ­çš„åœ¨ä¸Šé¢ï¼‰
    vpn_nodes.sort(key=lambda x: x['uptime_minutes'])

    # ç”Ÿæˆ Markdown å†…å®¹
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    md_content = f"# å®¶å®½ L2TP/IPsec VPN åˆ—è¡¨\n\n"
    md_content += f"> æ›´æ–°æ—¶é—´: {current_time} (UTC+0)\n"
    md_content += f"> æ•°æ®æ¥æº: [{TARGET_URL}]({TARGET_URL})\n\n"
    md_content += f"**æ’åºè§„åˆ™**ï¼šæŒ‰åœ¨çº¿æ—¶é—´å€’åºï¼ˆæ–°ä¸Šçº¿çš„èŠ‚ç‚¹åœ¨æœ€ä¸Šæ–¹ï¼‰ã€‚\n\n"
    
    md_content += "| åœ°åŒº | IP åœ°å€ | åœ¨çº¿æ—¶é—´ | å»¶è¿Ÿ (Ping) |\n"
    md_content += "| :--- | :--- | :--- | :--- |\n"

    for node in vpn_nodes:
        # åŠ ç²—æ˜¾ç¤ºè¿è¡Œæ—¶é—´å°‘äº 1 å¤© (1440åˆ†é’Ÿ) çš„èŠ‚ç‚¹
        uptime_display = node['uptime_str']
        if node['uptime_minutes'] < 1440:
            uptime_display = f"**{uptime_display}** ğŸ†•"

        md_content += f"| {node['location']} | `{node['ip']}` | {uptime_display} | {node['ping']} |\n"

    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•ï¼Œç¡®ä¿ README ç”Ÿæˆåœ¨ 'å®¶å®½' ç›®å½•ä¸‹
    script_dir = os.path.dirname(os.path.abspath(__file__))
    readme_path = os.path.join(script_dir, 'README.md')

    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(md_content)

    print(f"æˆåŠŸç”Ÿæˆ README.mdï¼Œå…± {len(vpn_nodes)} ä¸ªèŠ‚ç‚¹ã€‚")

if __name__ == "__main__":
    scrape_and_generate_readme()
